grad = function(X, y, theta){
X = as.matrix(X)
m = nrow(X)
hx = sigmoid(X %*% theta)
(1/m) * (t(X) %*% (hx - y))
}
maxinteration = 100000
for (i in 1:maxinteration){
theta = theta - alpha * grad(X, y, theta)
}
print(theta)
coef(mylogit)
theta<-matrix(rep(1,4),ncol = 1)
alpha <- 0.0001
y <- mydata$admit
sigmoid = function(z){
1 / (1 + exp(-z))
}
grad = function(X, y, theta){
X = as.matrix(X)
m = nrow(X)
hx = sigmoid(X %*% theta)
(1/m) * (t(X) %*% (hx - y))
}
maxinteration = 100000
for (i in 1:maxinteration){
theta = theta - alpha * grad(X, y, theta)
}
print(theta)
coef_logit
theta<-matrix(rep(1,4),ncol = 1)
alpha <- 0.00001
y <- mydata$admit
sigmoid = function(z){
1 / (1 + exp(-z))
}
grad = function(X, y, theta){
X = as.matrix(X)
m = nrow(X)
hx = sigmoid(X %*% theta)
(1/m) * (t(X) %*% (hx - y))
}
maxinteration = 100000
for (i in 1:maxinteration){
theta = theta - alpha * grad(X, y, theta)
}
print(theta)
coef(mylogit)
theta<-matrix(rep(1,4),ncol = 1)
alpha <- 0.00001
y <- mydata$admit
sigmoid = function(z){
1 / (1 + exp(-z))
}
grad = function(X, y, theta){
X = as.matrix(X)
m = nrow(X)
hx = sigmoid(X %*% theta)
(1/m) * (t(X) %*% (hx - y))
}
maxinteration = 1000000
for (i in 1:maxinteration){
theta = theta - alpha * grad(X, y, theta)
}
print(theta)
coef(mylogit)
X
theta<-matrix(rep(1,4),ncol = 1)
alpha <- 0.00001
y <- mydata$admit
X <- cbind(x0,mydata[,c(2,3,4)])
sigmoid = function(z){
1 / (1 + exp(-z))
}
grad = function(X, y, theta){
X = as.matrix(X)
m = nrow(X)
hx = sigmoid(X %*% theta)
(1/m) * (t(X) %*% (hx - y))
}
maxinteration = 1000000
for (i in 1:maxinteration){
theta = theta - alpha * grad(X, y, theta)
}
print(theta)
print(coef(mylogit))
theta<-matrix(rep(0,4),ncol = 1)
alpha <- 0.00001
y <- mydata$admit
X <- cbind(x0,mydata[,c(2,3,4)])
sigmoid = function(z){
1 / (1 + exp(-z))
}
grad = function(X, y, theta){
X = as.matrix(X)
m = nrow(X)
hx = sigmoid(X %*% theta)
(1/m) * (t(X) %*% (hx - y))
}
maxinteration = 10000
for (i in 1:maxinteration){
theta = theta - alpha * grad(X, y, theta)
}
print(theta)
print(coef(mylogit))
theta<-matrix(rep(0,4),ncol = 1)
alpha <- 0.001
y <- mydata$admit
X <- cbind(x0,mydata[,c(2,3,4)])
sigmoid = function(z){
1 / (1 + exp(-z))
}
grad = function(X, y, theta){
X = as.matrix(X)
m = nrow(X)
hx = sigmoid(X %*% theta)
(1/m) * (t(X) %*% (hx - y))
}
maxinteration = 10000
for (i in 1:maxinteration){
theta = theta - alpha * grad(X, y, theta)
}
print(theta)
print(coef(mylogit))
theta0<-matrix(rep(0,4),ncol = 1)
alpha <- 0.0001
y <- mydata$admit
X <- cbind(x0,mydata[,c(2,3,4)])
sigmoid = function(z){
1 / (1 + exp(-z))
}
grad = function(X, y, theta){
X = as.matrix(X)
m = nrow(X)
hx = sigmoid(X %*% theta)
(1/m) * (t(X) %*% (hx - y))
}
maxinteration = 10000
for (i in 1:maxinteration){
theta1 = theta - alpha * grad(X, y, theta)
if(sum(abs(theta1 - theta))/length(theta)<0.001) break
thetha = theta1
}
print(theta)
print(coef(mylogit))
theta0<-matrix(rep(0,4),ncol = 1)
alpha <- 0.001
y <- mydata$admit
X <- cbind(x0,mydata[,c(2,3,4)])
sigmoid = function(z){
1 / (1 + exp(-z))
}
grad = function(X, y, theta){
X = as.matrix(X)
m = nrow(X)
hx = sigmoid(X %*% theta)
(1/m) * (t(X) %*% (hx - y))
}
maxinteration = 10000
for (i in 1:maxinteration){
theta1 = theta - alpha * grad(X, y, theta)
if(sum(abs(theta1 - theta))/length(theta)<0.001) break
thetha = theta1
}
print(theta)
print(coef(mylogit))
i
theta0<-matrix(rep(0,4),ncol = 1)
alpha <- 0.001
y <- mydata$admit
X <- cbind(x0,mydata[,c(2,3,4)])
sigmoid = function(z){
1 / (1 + exp(-z))
}
grad = function(X, y, theta){
X = as.matrix(X)
m = nrow(X)
hx = sigmoid(X %*% theta)
(1/m) * (t(X) %*% (hx - y))
}
maxinteration = 100000
for (i in 1:maxinteration){
theta1 = theta - alpha * grad(X, y, theta)
if(sum(abs(theta1 - theta))/length(theta)<0.001) break
thetha = theta1
}
print(theta)
print(coef(mylogit))
sigmoid <- function(z) {
return(1/(1 + exp(-z)))
}
mapFeature <- function(X1, X2) {
degree <- 6
out <- rep(1, length(X1))
for (i in 1:degree) {
for (j in 0:i) {
out <- cbind(out, (X1^(i - j)) * (X2^j))
}
}
return(out)
}
fr <- function(theta, X, y, lambda) {
m <- length(y)
return(1/m * sum(-y * log(sigmoid(X %*% theta)) - (1 - y) *
log(1 - sigmoid(X %*% theta))) + lambda/2/m * sum(theta[-1]^2))
}
## Gradient
grr <- function(theta, X, y, lambda) {
return(1/m * t(X) %*% (sigmoid(X %*% theta) - y) + lambda/m *
c(0, theta[-1]))
}
data <- read.csv("ex2data2.txt", header = F)
getwd()
setwd('/Users/wenxuanzhang/LocalDoc/GitHub/R-basic')
data <- read.csv("ex2data2.txt", header = F)
ls
getwd()
ls
setwd('/Users/wenxuanzhang/LocalDoc/GitHub/R-basic')
getwd()
data <- read.csv("ex2data2.txt", header = F)
data <- read.csv("ex2data1.txt", header = F)
X = as.matrix(data[,c(1,2)])
y = data[,3]
X = mapFeature(X[,1],X[,2])
m <- nrow(X)
n <- ncol(X)
initial_theta = rep(0, n)
lambda <- 1
res <- optim(initial_theta, fr, grr, X, y, lambda,
method = "BFGS", control = list(maxit = 100000))
res
library(logistf)
install.packages('logistf')
iris$Species <- as.factor(iris$Species)
sapply(iris, class)
model1 <- glm(Species ~ ., data = irisdf, family = binomial)
model1 <- glm(Species ~ ., data = iris, family = binomial)
# Does not converge, throws warnings.
model2 <- logistf(Species ~ ., data = iris, family = binomial)
head(iris)
iris$Species <- as.factor(iris$Species)
sapply(iris, class)
model1 <- glm(Species ~ ., data = iris, family = binomial)
model2 <- logistf(Species ~ ., data = iris, family = binomial)
library(logistf)
model2 <- logistf(Species ~ ., data = iris, family = binomial)
summary(model1)
head(iris)
unique(iris$Species)
theta0<-matrix(rep(0,4),ncol = 1)
alpha <- 0.001
y <- mydata$admit
X <- cbind(x0,mydata[,c(2,3,4)])
sigmoid = function(z){
1 / (1 + exp(-z))
}
grad = function(X, y, theta){
X = as.matrix(X)
m = nrow(X)
hx = sigmoid(X %*% theta)
(1/m) * (t(X) %*% (hx - y))
}
maxinteration = 100000
for (i in 1:maxinteration){
theta1 = theta - alpha * grad(X, y, theta)
if(sum(abs(theta1 - theta))/length(theta)<0.001) break
thetha = theta1
}
print(theta)
print(coef(mylogit))
mylogit <- glm(admit ~ gre + gpa + rank, data = mydata, family = "binomial")
summary(mylogit)
help("optim")
sigmoid <- function(z) {
return(1/(1 + exp(-z)))
}
## Cost Function
fr <- function(theta, X, y, lambda) {
m <- length(y)
return(1/m * sum(-y * log(sigmoid(X %*% theta)) - (1 - y) *
log(1 - sigmoid(X %*% theta))) + lambda/2/m * sum(theta[-1]^2))
}
## Gradient
grr <- function(theta, X, y, lambda) {
return(1/m * t(X) %*% (sigmoid(X %*% theta) - y) + lambda/m *
c(0, theta[-1]))
}
y = mydata[,1]
x0 = rep(1,n)
X = cbind(x0,mydata[,c(2,3,4)])
sigmoid <- function(z) {
return(1/(1 + exp(-z)))
}
## Cost Function
fr <- function(theta, X, y, lambda) {
m <- length(y)
return(1/m * sum(-y * log(sigmoid(X %*% theta)) - (1 - y) *
log(1 - sigmoid(X %*% theta))) + lambda/2/m * sum(theta[-1]^2))
}
## Gradient
grr <- function(theta, X, y, lambda) {
return(1/m * t(X) %*% (sigmoid(X %*% theta) - y) + lambda/m *
c(0, theta[-1]))
}
y = mydata[,1]
x0 = rep(1,dim(mydta)[1])
sigmoid <- function(z) {
return(1/(1 + exp(-z)))
}
## Cost Function
fr <- function(theta, X, y, lambda) {
m <- length(y)
return(1/m * sum(-y * log(sigmoid(X %*% theta)) - (1 - y) *
log(1 - sigmoid(X %*% theta))) + lambda/2/m * sum(theta[-1]^2))
}
## Gradient
grr <- function(theta, X, y, lambda) {
return(1/m * t(X) %*% (sigmoid(X %*% theta) - y) + lambda/m *
c(0, theta[-1]))
}
y = mydata[,1]
x0 = rep(1,dim(mydata)[1])
X = cbind(x0,mydata[,c(2,3,4)])
m <- nrow(X)
n <- ncol(X)
initial_theta = rep(0, n)
lambda <- 1
res <- optim(initial_theta, fr, grr, X, y, lambda,
method = "BFGS", control = list(maxit = 100000))
dim(x)
dim(x)
dim(X)
dim(y)
sigmoid <- function(z) {
return(1/(1 + exp(-z)))
}
## Cost Function
fr <- function(theta, X, y, lambda) {
m <- length(y)
return(1/m * sum(-y * log(sigmoid(X %*% theta)) - (1 - y) *
log(1 - sigmoid(X %*% theta))) + lambda/2/m * sum(theta[-1]^2))
}
## Gradient
grr <- function(theta, X, y, lambda) {
return(1/m * t(X) %*% (sigmoid(X %*% theta) - y) + lambda/m *
c(0, theta[-1]))
}
y = mydata[,1]
x0 = rep(1,dim(mydata)[1])
X = cbind(x0,mydata[,c(2,3,4)])
m <- nrow(X)
n <- ncol(X)
initial_theta = matrix(rep(0, n),nrow = n)
lambda <- 1
res <- optim(initial_theta, fr, grr, X, y, lambda,
method = "BFGS", control = list(maxit = 100000))
theta
res <- optim(initial_theta, fr, grr, X, y, lambda,
method = "BFGS", control = list(maxit = 100000))
#estimate coef by gradient
# start
sigmoid <- function(z)
{
g <- 1/(1+exp(-z))
return(g)
}
X <- as.matrix(mydata[,c(2,3,4)])
#Add ones to X
X <- cbind(rep(1,nrow(X)),X)
#Response variable
Y <- as.matrix(mydata$admit)
cost <- function(theta)
{
m <- nrow(X)
g <- sigmoid(X%*%theta)
J <- (1/m)*sum((-Y*log(g)) - ((1-Y)*log(1-g)))
return(J)
}
initial_theta <- rep(0,ncol(X))
#Cost at inital theta
cost(initial_theta)
theta_optim <- optim(par=initial_theta,fn=cost)
#set theta
theta <- theta_optim$par
theta_optim$value
print(theta)
print(coef_logit)
knitr::opts_chunk$set(echo = TRUE)
data(economics, package="ggplot2")  # load data
economics$index <- 1:nrow(economics)  # create index variable
economics <- economics[1:80, ]  # retail 80rows for better graphical understanding
loessMod10 <- loess(uempmed ~ index, data=economics, span=0.10) # 10% smoothing span
loessMod25 <- loess(uempmed ~ index, data=economics, span=0.25) # 25% smoothing span
loessMod50 <- loess(uempmed ~ index, data=economics, span=0.50) #
smoothed10 <- predict(loessMod10)
smoothed25 <- predict(loessMod25)
smoothed50 <- predict(loessMod50)
plot(economics$uempmed, x=economics$date, type="l", main="Loess Smoothing and Prediction", xlab="Date", ylab="Unemployment (Median)")
lines(smoothed10, x=economics$date, col="red")
lines(smoothed25, x=economics$date, col="green")
lines(smoothed50, x=economics$date, col="blue")
calcSSE <- function(x){
loessMod <- try(loess(uempmed ~ index, data=economics, span=x), silent=T)
res <- try(loessMod$residuals, silent=T)
if(class(res)!="try-error"){
if((sum(res, na.rm=T) > 0)){
sse <- sum(res^2)
}
}else{
sse <- 99999
}
return(sse)
}
optim(par=c(0.5), calcSSE, method="SANN")
calcSSE <- function(x){
loessMod <- try(loess(uempmed ~ index, data=economics, span=x), silent=T)
res <- try(loessMod$residuals, silent=T)
if(class(res)!="try-error"){
if((sum(res, na.rm=T) > 0)){
sse <- sum(res^2)
}
}else{
sse <- 99999
}
return(sse)
}
optim(par=c(0.5), calcSSE, method="SANN")
loessMod <- try(loess(uempmed ~ index, data=economics, span=x), silent=T)
res <- try(loessMod$residuals, silent=T)
sse <- sum(res^2)
res
x = 0.5
loessMod <- try(loess(uempmed ~ index, data=economics, span=x), silent=T)
res <- try(loessMod$residuals, silent=T)
if(class(res)!="try-error"){
if((sum(res, na.rm=T) > 0)){
sse <- sum(res^2)
}
}else{
sse <- 99999
}
sse
res
sse <- sum(res^2)
sse
calcSSE <- function(x){
loessMod <- try(loess(uempmed ~ index, data=economics, span=x), silent=T)
res <- try(loessMod$residuals, silent=T)
if(class(res)!="try-error"){
if((sum(res, na.rm=T) > 0)){
sse <- sum(res^2)
}
}else{
sse <- 99999
}
return(sse)
}
optim(par=c(0.5), calcSSE, method="SANN")
knitr::opts_chunk$set(echo = TRUE)
data(economics, package="ggplot2")  # load data
economics$index <- 1:nrow(economics)  # create index variable
economics <- economics[1:80, ]  # retail 80rows for better graphical understanding
loessMod10 <- loess(uempmed ~ index, data=economics, span=0.10) # 10% smoothing span
loessMod25 <- loess(uempmed ~ index, data=economics, span=0.25) # 25% smoothing span
loessMod50 <- loess(uempmed ~ index, data=economics, span=0.50) #
smoothed10 <- predict(loessMod10)
smoothed25 <- predict(loessMod25)
smoothed50 <- predict(loessMod50)
plot(economics$uempmed, x=economics$date, type="l", main="Loess Smoothing and Prediction", xlab="Date", ylab="Unemployment (Median)")
lines(smoothed10, x=economics$date, col="red")
lines(smoothed25, x=economics$date, col="green")
lines(smoothed50, x=economics$date, col="blue")
# define function that returns the SSE,
calcSSE <- function(x){
loessMod <- try(loess(uempmed ~ index, data=economics, span=x), silent=T)
res <- try(loessMod$residuals, silent=T)
if(class(res)!="try-error"){
if((sum(res, na.rm=T) > 0)){
sse <- sum(res^2)
}
}else{
sse <- 99999
}
return(sse)
}
optim(par=c(0.5), calcSSE, method="SANN")
final<-0.07416657
#define k-fold cross validation method
ctrl <- trainControl(method = "cv", number = 5)
library(caret)
# find k fold optimization
#define k-fold cross validation method
ctrl <- trainControl(method = "cv", number = 5)
grid <- expand.grid(span = seq(0.5, 0.9, len = 5), degree = 1)
#perform cross-validation using smoothing spans ranginf from 0.5 to 0.9
model <- train(uempmed ~ index, data = economics, method = "gamLoess", tuneGrid=grid, trControl = ctrl)
ctrl <- trainControl(method = "cv", number = 5)
grid <- expand.grid(span = seq(0.5, 0.9, len = 5), degree = 1)
#perform cross-validation using smoothing spans ranginf from 0.5 to 0.9
model <- train(uempmed ~ index, data = economics, method = "gamLoess", tuneGrid=grid, trControl = ctrl)
install.packages('gam')
install.packages('gam')
install.packages('gam')
updateR()
library(installR)
library(installR)
library(installr)
install.packages('installr')
library(installr)
updateR()
version
